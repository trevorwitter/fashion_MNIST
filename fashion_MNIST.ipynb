{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('fashion-mnist_train.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train.drop('label', axis=1).as_matrix()\n",
    "y_train = train['label'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784) , y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape, \", y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('fashion-mnist_test.csv', header=0)\n",
    "X_test = test.drop('label', axis=1).as_matrix()\n",
    "y_test = test['label'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (10000, 784) , y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test shape:\", X_test.shape, \", y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQCjKD4Si/EAoyg+EovxAqP8B6e5kLJbyDuwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128569ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = X_train[5002]\n",
    "test_digit_image = test_image.reshape(28,28)\n",
    "\n",
    "plt.imshow(test_digit_image, cmap=matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[5002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/python3/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([X_train[5002]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.74 s, sys: 498 ms, total: 7.24 s\n",
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y_scores_sgd = cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 544 ms, total: 22.6 s\n",
      "Wall time: 5.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "y_scores_forest = cross_val_score(forest_clf, X_train, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 18min 56s, sys: 7.16 s, total: 1h 19min 4s\n",
      "Wall time: 10min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1)\n",
    "y_scores_knn = cross_val_score(knn_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: [ 0.77445  0.8003   0.8073 ]\n",
      "Random Forest: [ 0.85425  0.85415  0.8562 ]\n",
      "KNN: [ 0.8478   0.85445  0.8543 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"SGD:\", y_scores_sgd)\n",
    "print(\"Random Forest:\", y_scores_forest)\n",
    "print(\"KNN:\", y_scores_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on initial accuracy scores, the random forest and k-nearest neighbors classifiers performed better than the stochastic gradient decent classifier. I selected the random forest model as it performed roughly the same as the k-nearest neighbors classifier and ran approximately 250 times faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [180, 200, 220, 240], 'max_features': [20, 30, 35]}, {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'n_estimators':[180,200,220,240], 'max_features':[20,30,35]},\n",
    "              {'bootstrap':[False], 'n_estimators':[3,10], 'max_features':[2,3,4]},\n",
    "             ]\n",
    "\n",
    "grid_search = GridSearchCV(forest_clf, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879433333333 {'n_estimators': 180, 'max_features': 20}\n",
      "0.879866666667 {'n_estimators': 200, 'max_features': 20}\n",
      "0.879833333333 {'n_estimators': 220, 'max_features': 20}\n",
      "0.879916666667 {'n_estimators': 240, 'max_features': 20}\n",
      "0.880616666667 {'n_estimators': 180, 'max_features': 30}\n",
      "0.880516666667 {'n_estimators': 200, 'max_features': 30}\n",
      "0.88055 {'n_estimators': 220, 'max_features': 30}\n",
      "0.880133333333 {'n_estimators': 240, 'max_features': 30}\n",
      "0.881216666667 {'n_estimators': 180, 'max_features': 35}\n",
      "0.881633333333 {'n_estimators': 200, 'max_features': 35}\n",
      "0.881166666667 {'n_estimators': 220, 'max_features': 35}\n",
      "0.881966666667 {'n_estimators': 240, 'max_features': 35}\n",
      "0.7626 {'bootstrap': False, 'n_estimators': 3, 'max_features': 2}\n",
      "0.83255 {'bootstrap': False, 'n_estimators': 10, 'max_features': 2}\n",
      "0.768916666667 {'bootstrap': False, 'n_estimators': 3, 'max_features': 3}\n",
      "0.834 {'bootstrap': False, 'n_estimators': 10, 'max_features': 3}\n",
      "0.783283333333 {'bootstrap': False, 'n_estimators': 3, 'max_features': 4}\n",
      "0.842483333333 {'bootstrap': False, 'n_estimators': 10, 'max_features': 4}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88196666666666668"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 35, 'n_estimators': 240}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For converting numeric labels to text\n",
    "labels = {0:\"T-shirt/top\", \n",
    "          1:\"Trouser\", \n",
    "          2:\"Pullover\", \n",
    "          3:\"Dress\", \n",
    "          4:\"Coat\", \n",
    "          5:\"Sandal\", \n",
    "          6:\"Shirt\", \n",
    "          7:\"Sneaker\", \n",
    "          8:\"Bag\", \n",
    "          9:\"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "def label_clothing(indexes):\n",
    "    \"\"\"Prints label prediction based on clothing image and correct answer\n",
    "    based on y_test labels\"\"\"\n",
    "    for x in indexes:\n",
    "        pred = final_model.predict([X_test[x]])\n",
    "        correct = y_test[x]\n",
    "        print(\"Prediction:\", labels[pred[0]], \"Correct Answer:\", labels[correct])\n",
    "        #print(\"prediction:\", final_model.predict(X_test[x].reshape(1,-1)), \n",
    "        #      \"Correct Answer:\", y_test[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Ankle boot Correct Answer: Ankle boot\n",
      "Prediction: Dress Correct Answer: Dress\n",
      "Prediction: Shirt Correct Answer: Dress\n",
      "Prediction: Sneaker Correct Answer: Sneaker\n",
      "Prediction: Pullover Correct Answer: Pullover\n",
      "Prediction: Sneaker Correct Answer: Ankle boot\n",
      "Prediction: Trouser Correct Answer: Trouser\n",
      "Prediction: T-shirt/top Correct Answer: T-shirt/top\n",
      "Prediction: Bag Correct Answer: Bag\n",
      "Prediction: Coat Correct Answer: Coat\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "numbers = random.sample(range(0,10000), 10)\n",
    "\n",
    "label_clothing(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest algorithm is great general purpose algorithm for a number of reasons:\n",
    "* Requires minimal tuning\n",
    "* Requires minimal feature preprocessing\n",
    "* Is capable of feature selection\n",
    "* Is quicker than similar performing algorithms such as KNN\n",
    "\n",
    "Though this model performs moderately well (88% accuracy), I will explore other options such as neural networks as a next step to see if I can increase the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
